{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-NN classifier yielded a 3.09% test error rate on the MNIST data set of handwritten digits. We will now see that a Gaussian generative model does almost as well, while being significantly faster and more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import sys\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAFL0lEQVR4nO3dsWtTawDG4Xsu0iB1qCB2Ka7dO6eSKW6KCPUPaBeHTl26dClYpFtXl4yCaxcHRQyOWQTBP6CT6FCk0KHSc6c73Zzv2rRN3qTPM+Ylybf8+MBDY1XX9V9Anr8nfQBgOHFCKHFCKHFCKHFCqFulsaoq/5QL16yu62rY625OCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCHVr0gcgy87OTuO2u7tbfO/Xr1+L+97eXnF/8+ZNcb9p3JwQSpwQSpwQSpwQSpwQSpwQSpwQqqrrunmsquZxhr18+bK4v337trh/+fLlKo9zpVqtVnH/+fNn4zY/P3+p7+73+8W90+lc6vOnVV3X1bDX3ZwQSpwQSpwQSpwQSpwQSpwQamb/ZOzu3buN2+PHj4vvffHiRXHf2Ngo7ktLS8X97OysuE/SZR+XcHXcnBBKnBBKnBBKnBBKnBBKnBBKnBBqZp9zLi8vN269Xu9av7uqhv4FEFyImxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCzezv1k7So0ePivvh4eGYTsI0c3NCKHFCKHFCKHFCKHFCKHFCqJl9lNJutyf23VtbW8X948ePjdvJyUnxvU+fPi3uDx48KO5Pnjwp7uRwc0IocUIocUIocUIocUIocUIocUKoqq7r5rGqmsdwnz59atxWV1fHeJL/+v79e+P2+/fv4nvv3btX3Fut1khnGodut1vc379/P6aTZKnruhr2upsTQokTQokTQokTQokTQokTQokTQk3t33M+fPiwuK+srIzpJBe3uLg46SNMxK9fvyZ9hKni5oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQU/uc89u3b8X98+fPjdv//Rd9jOb4+Li4LywsjOkks8HNCaHECaHECaHECaHECaHECaHECaFm9ndrS7/v+vz58+J7t7e3r/o4V+b169fF/cePH8V9f3+/uN+5c+fCZ/rX0dFRcR8MBsX92bNnI3/3NPO7tTBlxAmhxAmhxAmhxAmhxAmhZvZRCsMdHBwU983NzWv77n6/X9w7nc61fXcyj1JgyogTQokTQokTQokTQokTQokTQk3tT2Mymg8fPhT363zOycW4OSGUOCGUOCGUOCGUOCGUOCGUOCGU55w3TLvdnvQR+ENuTgglTgglTgglTgglTgglTgglTgjlOecN02q1Jn0E/pCbE0KJE0KJE0KJE0KJE0KJE0J5lDJj7t+/X9zX1tbGdBIuy80JocQJocQJocQJocQJocQJocQJoTznnDFzc3PFfXFxcUwn4bLcnBBKnBBKnBBKnBBKnBBKnBBKnBDKc84Zc35+XtxPT0+L++3bt0f+7sFgUNxfvXo18mffRG5OCCVOCCVOCCVOCCVOCCVOCCVOCFXVdd08VlXzyFTqdrvF/d27dyN/9vr6enHv9Xojf/Ysq+u6Gva6mxNCiRNCiRNCiRNCiRNCiRNCiRNCec4JE+Y5J0wZcUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUKo4k9jApPj5oRQ4oRQ4oRQ4oRQ4oRQ4oRQ/wBCdqRBiWK5UQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the Winery example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a parameter, and by setting it appropriately, we can improve the performance of the model. We will study **regularization** in greater detail over the coming weeks.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y, constant=1000):\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    for label in range(0,k):\n",
    "        indices = (y == label)\n",
    "        mu[label] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar=0, bias=1) + constant*np.eye(784) #regularized\n",
    "        pi[label] = float(sum(indices))/float(len(y)) \n",
    "    \n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "def compute_error(test_labels, mu, sigma, pi):\n",
    "    \n",
    "    k=10\n",
    "    score = np.zeros((len(test_labels),k))\n",
    "    for label in range(0,k):\n",
    "        rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "        for i in range(0,len(test_labels)):\n",
    "           score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "    predictions = np.argmax(score, axis=1)\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != test_labels)\n",
    "    #print (\"Your model makes \" + str(errors) + \" errors out of 10000\")\n",
    "    return errors\n",
    "    \n",
    "errors = compute_error(test_labels, mu, sigma, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.000000e+00, 1.482000e+03],\n",
       "       [4.000000e+00, 1.366000e+03],\n",
       "       [8.000000e+00, 1.249000e+03],\n",
       "       [1.600000e+01, 1.153000e+03],\n",
       "       [3.200000e+01, 1.018000e+03],\n",
       "       [6.400000e+01, 8.940000e+02],\n",
       "       [1.280000e+02, 7.660000e+02],\n",
       "       [2.560000e+02, 6.480000e+02],\n",
       "       [5.120000e+02, 5.580000e+02],\n",
       "       [1.024000e+03, 4.860000e+02],\n",
       "       [2.048000e+03, 4.360000e+02],\n",
       "       [4.096000e+03, 4.310000e+02],\n",
       "       [8.192000e+03, 4.920000e+02],\n",
       "       [1.638400e+04, 5.980000e+02],\n",
       "       [3.276800e+04, 8.010000e+02],\n",
       "       [6.553600e+04, 1.155000e+03],\n",
       "       [1.310720e+05, 1.634000e+03],\n",
       "       [2.621440e+05, 2.190000e+03],\n",
       "       [5.242880e+05, 2.807000e+03],\n",
       "       [1.048576e+06, 3.466000e+03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_matrix = np.zeros((20,2))\n",
    "for i in range (1, 21):\n",
    "    error_matrix[i-1,0] = 2 ** i\n",
    "    mu, sigma, pi = fit_generative_model(train_data, train_labels, constant = 2**i)\n",
    "    error_matrix[i-1,1] = compute_error(test_labels, mu, sigma, pi)\n",
    "    \n",
    "error_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2  1482\n",
      "    4  1366\n",
      "    8  1249\n",
      "   16  1153\n",
      "   32  1018\n",
      "   64   894\n",
      "  128   766\n",
      "  256   648\n",
      "  512   558\n",
      " 1024   486\n",
      " 2048   436\n",
      " 4096   431\n",
      " 8192   492\n",
      "16384   598\n",
      "32768   801\n",
      "65536  1155\n",
      "131072  1634\n",
      "262144  2190\n",
      "524288  2807\n",
      "1048576  3466\n"
     ]
    }
   ],
   "source": [
    "np.savetxt(sys.stdout, error_matrix, '%5.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You will need to answer variants of these questions as part of this week's assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices?\n",
    "\n",
    "LinAlgErro - Singular matrix, because of sigma is not invertable (values are too close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens?\n",
    "\n",
    "Large amount of errors 7929/10000 @ c=10000000. 1226/100000 @ c=10. 489/10000 @ c=1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the training set?\n",
    "\n",
    "Used 1000, it appears that 1000-10000 give similar values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">If you have the time</font>: We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
